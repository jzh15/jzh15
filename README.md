<div align="center">

# ğŸŒŸ Jian Zhang | å¼ èˆ°

<img src="https://readme-typing-svg.herokuapp.com?font=Space+Grotesk&size=30&duration=3000&pause=1000&color=00D9FF&center=true&vCenter=true&width=600&lines=Exploring+3D-Consistent+Generation;Advancing+3D+Spatial+Understanding;Building+Intelligent+3D+Agents" alt="Typing SVG" />

[![Homepage](https://img.shields.io/badge/ğŸŒ_Homepage-Visit_Site-00D9FF?style=for-the-badge&logo=github-pages)](https://jzh15.github.io/)
[![Google Scholar](https://img.shields.io/badge/ğŸ“š_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=qBNtBsAAAAAJ)
[![CV](https://img.shields.io/badge/ğŸ“„_CV-Download-FF6B6B?style=for-the-badge&logo=adobe-acrobat-reader)](cv/Resume_Jian_Zhang.pdf)
[![Email](https://img.shields.io/badge/ğŸ“§_Email-Contact-FFA726?style=for-the-badge&logo=gmail&logoColor=white)](mailto:zjrandomyeah@gmail.com)

</div>

---

<table>
<tr>
<td width="30%" align="center">

<img src="jian_zhang.jpg" alt="Jian Zhang" width="180" style="border-radius: 15px;">

<br>

**ğŸ“ Graduate Student**  
*Xiamen University*

</td>
<td width="70%">

## ğŸš€ Research Vision

> *My long-term vision follows a progressive pathway: first achieving **3D-consistent content generation**, then developing comprehensive **3D understanding**, and ultimately enabling intelligent **embodied agents** that can navigate and interact within these 3D environments.*

### ğŸ¯ Current Focus Areas

- **ğŸ¬ 3D-Consistent Content Generation**
- **ğŸ”¬ 3D Spatial Understanding** 
- **ğŸ¤– 3D Embodied Agents**
- **ğŸ® Virtual Worlds & Metaverse Applications**

</td>
</tr>
</table>

---

## ğŸ“ Education

- **Graduate Student** | *Xiamen University* (Sept 2023 - Present)
- **B.S. Artificial Intelligence** | *Nanchang University* (Sept 2019 - June 2023)

## ğŸ’¼ Experience

- **Research Assistant** | *Texas A&M University* (May 2025 - Aug 2025) - 3D Vision & Embodied Intelligence
- **Research Assistant** | *VITA Group, University of Texas at Austin* (Jan 2024 - May 2025) - 3D Spatial Reconstruction & Understanding

---

## ğŸ“š Featured Publications

<div align="center">

### ğŸ”¥ **Recent Highlights**

</div>

### ğŸŒŸ VLM-3R: Vision-Language Models Augmented with 3D Reconstruction
**ArXiv 2025** | **Jian Zhang***, Zhiwen Fan*, et al.

Unified VLM framework incorporating 3D Reconstructive instruction tuning, processing monocular video to derive implicit 3D tokens for spatial assistance and embodied reasoning.

[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-ArXiv-B31B1B?style=flat-square)](https://arxiv.org/abs/2505.20279)
[![Code](https://img.shields.io/badge/ğŸ’»_Code-GitHub-000000?style=flat-square&logo=github)](https://github.com/VITA-Group/VLM-3R)
[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://vlm-3r.github.io/)
[![Demo](https://img.shields.io/badge/ğŸ®_Demo-Interactive-FF6B6B?style=flat-square)](https://vlm-3r.github.io/)

---

### ğŸŒ DynamicVerse: Physically-Aware Multimodal Modeling for Dynamic 4D Worlds
**Preprint** | Kairun Wen*, Yuzhi Huang*, ..., **Jian Zhang**, et al.

Large-scale dataset with 100K+ videos, 800K+ masks, and 10M+ frames for understanding dynamic physical worlds with evolving 3D structure and motion.

[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://dynamic-verse.github.io/)
[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-Coming_Soon-gray?style=flat-square)]()
[![Code](https://img.shields.io/badge/ğŸ’»_Code-Coming_Soon-gray?style=flat-square)]()
[![Demo](https://img.shields.io/badge/ğŸ®_Demo-Interactive-FF6B6B?style=flat-square)](https://dynamic-verse.github.io/)

---

### ğŸ† Large Spatial Model: End-to-end Unposed Images to Semantic 3D
**NeurIPS 2024** | **Jian Zhang***, Zhiwen Fan*, et al.

First real-time semantic 3D reconstruction system that directly processes unposed RGB images into semantic radiance fields in a single feed-forward pass.

[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-NeurIPS-B31B1B?style=flat-square)](https://arxiv.org/abs/2410.18956)
[![Code](https://img.shields.io/badge/ğŸ’»_Code-GitHub-000000?style=flat-square&logo=github)](https://github.com/NVlabs/LSM)
[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://largespatialmodel.github.io/)

---

### âš¡ InstantSplat: Sparse-view Gaussian Splatting in Seconds
**ArXiv 2024** | Zhiwen Fan*, Kairun Wen*, ..., **Jian Zhang**, et al.

Lightning-fast sparse-view 3D scene reconstruction using self-supervised framework that optimizes 3D scene representation and camera poses simultaneously.

[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-ArXiv-B31B1B?style=flat-square)](https://arxiv.org/abs/2403.20309)
[![Code](https://img.shields.io/badge/ğŸ’»_Code-GitHub-000000?style=flat-square&logo=github)](https://github.com/NVlabs/InstantSplat)
[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://instantsplat.github.io/)

---

---

## ğŸŒŸ Open for Opportunities

<div align="center">

<table>
<tr>
<td align="center" width="33%">
<h3>ğŸ¬</h3>
<b>3D-Consistent Video Generation</b>
<br><sub>Creating spatially coherent visual content</sub>
</td>
<td align="center" width="33%">
<h3>ğŸ”¬</h3>
<b>3D Spatial Understanding</b>
<br><sub>Developing comprehensive 3D perception</sub>
</td>
<td align="center" width="33%">
<h3>ğŸ¤</h3>
<b>Research Collaborations</b>
<br><sub>Building the future of 3D AI together</sub>
</td>
</tr>
</table>

*Particularly interested in opportunities that bridge cutting-edge research with real-world applications.*

</div>

---

## ğŸ“« Contact

<div align="center">

[![Email](https://img.shields.io/badge/ğŸ“§_zjrandomyeah@gmail.com-FFA726?style=for-the-badge&logo=gmail&logoColor=white)](mailto:zjrandomyeah@gmail.com)

---

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12&height=100&section=footer&text=Thanks%20for%20visiting!&fontSize=16&fontColor=ffffff">
  <source media="(prefers-color-scheme: light)" srcset="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12&height=100&section=footer&text=Thanks%20for%20visiting!&fontSize=16&fontColor=333333">
  <img alt="Thanks for visiting!" src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12&height=100&section=footer&text=Thanks%20for%20visiting!&fontSize=16&fontColor=333333" width="100%">
</picture>

*Building the future of 3D AI, one breakthrough at a time* âœ¨

</div>
